{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FapAt23q5a6y",
    "outputId": "a0cd16c0-c32c-4373-e738-1be89ab20797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "45ikxq4CLg2t"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyCt_ZFCLFhE",
    "outputId": "6232c573-c542-4174-b120-f469cba03c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-6fj6jhzy\n",
      "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-6fj6jhzy\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /usr/local/lib/python3.7/dist-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (7.1.2)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (2.4.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface==0.6) (3.13)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp37-none-any.whl size=8312 sha256=03163efc15abd5ec9cdbbe6dfcb336bdff045a8baaa6714208cfb3ded573ee2f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p1tv46h9/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n",
      "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
      "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
      "Requirement already satisfied: keras in /tensorflow-1.15.2/python3.7 (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras) (1.15.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "!sudo pip install mtcnn\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BYLSTaN-JxIB"
   },
   "outputs": [],
   "source": [
    "# example of face detection with mtcnn\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "D9pAf3SR4zks"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "h2MHGvriLFE1",
    "outputId": "7550f5ff-62bd-4bfc-e63c-42c935a7ea00"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n# extract a single face from a given photograph\\ndef extract_face(filename, required_size=(224, 224)):\\n\\t# load image from file\\n\\tpixels = pyplot.imread(filename)\\n\\t# create the detector, using default weights\\n\\tdetector = MTCNN()\\n\\t# detect faces in the image\\n\\tresults = detector.detect_faces(pixels)\\n\\t# extract the bounding box from the first face\\n\\tx1, y1, width, height = results[0]['box']\\n\\tx2, y2 = x1 + width, y1 + height\\n\\t# extract the face\\n\\tface = pixels[y1:y2, x1:x2]\\n\\t# resize pixels to the model size\\n\\timage = Image.fromarray(face)\\n\\timage = image.resize(required_size)\\n\\tface_array = asarray(image)\\n\\treturn face_array\\n\\n# load the photo and extract the face\\npixels = extract_face('sharon_stone1.jpg')\\n\\n# convert one face into samples\\npixels = pixels.astype('float32')\\nsamples = expand_dims(pixels, axis=0)\\n# prepare the face for the model, e.g. center pixels\\nsamples = preprocess_input(samples, version=2)\\n# create a vggface model\\nmodel = VGGFace(model='resnet50')\\n# perform prediction\\nyhat = model.predict(samples)\\n# convert prediction into names\\nresults = decode_predictions(yhat)\\n# display most likely results\\nfor result in results[0]:\\n\\tprint('%s: %.3f%%' % (result[0], result[1]*100))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('sharon_stone1.jpg')\n",
    "\n",
    "# convert one face into samples\n",
    "pixels = pixels.astype('float32')\n",
    "samples = expand_dims(pixels, axis=0)\n",
    "# prepare the face for the model, e.g. center pixels\n",
    "samples = preprocess_input(samples, version=2)\n",
    "# create a vggface model\n",
    "model = VGGFace(model='resnet50')\n",
    "# perform prediction\n",
    "yhat = model.predict(samples)\n",
    "# convert prediction into names\n",
    "results = decode_predictions(yhat)\n",
    "# display most likely results\n",
    "for result in results[0]:\n",
    "\tprint('%s: %.3f%%' % (result[0], result[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MWe4sqbWXWm0"
   },
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AV-Moq1V47k-"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(filenames):\n",
    "\t# extract faces\n",
    "\tfaces = [extract_face(f) for f in filenames]\n",
    "\t# convert into an array of samples\n",
    "\tsamples = asarray(faces, 'float32')\n",
    "\t# prepare the face for the model, e.g. center pixels\n",
    "\tsamples = preprocess_input(samples, version=2)\n",
    "\t# create a vggface model\n",
    "\tmodel = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\t# perform prediction\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DVOD03Uc4-Vf"
   },
   "outputs": [],
   "source": [
    "def is_match_target1(known_embedding, candidate_embedding, thresh=0.5):\n",
    "  # calculate distance between embeddings\n",
    "  score1 = cosine(known_embedding, candidate_embedding)\n",
    "  return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JZUPNmflIMej"
   },
   "outputs": [],
   "source": [
    "def is_match_target2(known_embedding, candidate_embedding, thresh=0.5):\n",
    "  # calculate distance between embeddings\n",
    "  score2 = cosine(known_embedding, candidate_embedding)\n",
    "  return score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8aHhG0KtG-tq"
   },
   "outputs": [],
   "source": [
    "def isRight(i,score1, score2, thresh=0.5):\n",
    "  if score1 <= thresh:\n",
    "    print('>face ', i,' is Match target1(%.3f <= %.3f)' % (score1, thresh))\n",
    "  elif score2 <= thresh:\n",
    "    print('>face ', i,' is Match target2(%.3f <= %.3f)' % (score2, thresh))\n",
    "  else:\n",
    "    print(\"face \", i,\" is NOT Match... target1's score: %.3f and target2's score: %.3f <=  %.3f\" % (score1, score2, thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsA15UWX5ByX"
   },
   "outputs": [],
   "source": [
    "filenames = ['/Training_data/sharon_stone1.jpg',  \n",
    "             '/Training_data/channing_tatum.jpg', \n",
    "             '/Training_data/sharon_stone2.jpg',\n",
    "             '/Training_data/sharon_stone3.jpg',\n",
    "             '/Training_data/koreafish.jpg',\n",
    "             '/Training_data/channing_tatum.jpg']\n",
    "# get embeddings file filenames\n",
    "embeddings = get_embeddings(filenames)\n",
    "# define sharon stone\n",
    "target1 = embeddings[0]\n",
    "target2 = embeddings[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "te75ADHPC1i6",
    "outputId": "0fd1a051-f69e-43e0-8b90-fbc33df9b498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Test...\n",
      "5\n",
      ">face  0  is a Match Z.T Yang(0.000 <= 0.500)\n",
      ">face  1  is a Match W.R Chen(0.000 <= 0.500)\n",
      ">face  2  is a Match Z.T Yang(0.161 <= 0.500)\n",
      ">face  3  is a Match W.R Chen(0.446 <= 0.500)\n",
      "face  4  is NOT a Match... W.R Chens's score: 0.794 and Z.T Yang's score: 0.788 <=  0.500\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nis_match(target_id, embeddings[1])\\nis_match(target_id, embeddings[2])\\n# verify known photos of other people\\nprint('Negative Tests')\\nis_match(target_id, embeddings[3])\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify known photos of sharon\n",
    "print('Object Test...')\n",
    "print(len(filenames))\n",
    "for i in range(len(filenames)):\n",
    "  score1 = is_match_target1(target1, embeddings[i])\n",
    "  score2 = is_match_target2(target2, embeddings[i])\n",
    "  isRight(i, score1, score2)\n",
    "'''\n",
    "is_match(target_id, embeddings[1])\n",
    "is_match(target_id, embeddings[2])\n",
    "# verify known photos of other people\n",
    "print('Negative Tests')\n",
    "is_match(target_id, embeddings[3])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T92d2O6pM3oz"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('sharon_stone1.jpg')\n",
    "\n",
    "# plot the extracted face\n",
    "pyplot.imshow(pixels)\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "# convert one face into samples\n",
    "pixels = pixels.astype('float32')\n",
    "samples = expand_dims(pixels, axis=0)\n",
    "# prepare the face for the model, e.g. center pixels\n",
    "samples = preprocess_input(samples, version=2)\n",
    "# create a vggface model\n",
    "model = VGGFace(model='resnet50')\n",
    "# perform prediction\n",
    "yhat = model.predict(samples)\n",
    "# convert prediction into names\n",
    "results = decode_predictions(yhat)\n",
    "# display most likely results\n",
    "for result in results[0]:\n",
    "\tprint('%s: %.3f%%' % (result[0], result[1]*100))\n",
    "\n",
    "\n",
    "# Example of face detection with a vggface2 model\n",
    "\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('/content/drive/MyDrive/Training-Data/CNN-face-recognition/channing_tatum.jpg')\n",
    "# plot the extracted face\n",
    "pyplot.imshow(pixels)\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# create a vggface2 model\n",
    "model = VGGFace(model='resnet50')\n",
    "# summarize input and output shape\n",
    "print('Inputs: %s' % model.inputs)\n",
    "print('Outputs: %s' % model.outputs)\n",
    "# convert one face into samples\n",
    "pixels = pixels.astype('float32')\n",
    "samples = expand_dims(pixels, axis=0)\n",
    "# prepare the face for the model, e.g. center pixels\n",
    "samples = preprocess_input(samples, version=2)\n",
    "# create a vggface model\n",
    "model = VGGFace(model='resnet50')\n",
    "# perform prediction\n",
    "yhat = model.predict(samples)\n",
    "# convert prediction into names\n",
    "results = decode_predictions(yhat)\n",
    "# display most likely results\n",
    "for result in results[0]:\n",
    "\tprint('%s: %.3f%%' % (result[0], result[1]*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NN Class Active 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
